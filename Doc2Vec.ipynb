{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shengyuan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "english_stemmer=nltk.stem.SnowballStemmer('english')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import silhouette_score\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir,round,args):\n",
    "    data = []\n",
    "    data_args = []\n",
    "    for i in range(1,6):\n",
    "        with open(os.path.join(dir,'r%d/%d.json'%(round,i)),'r') as d:\n",
    "            tem_data = json.load(d)\n",
    "        data.extend(tem_data['result']['docs'])\n",
    "    for i in range(len(data)):\n",
    "        data_args.append(data[i][args])\n",
    "        data_args = list(set(data_args))\n",
    "    return data_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "dir='/Users/shengyuan/Desktop/Study/CAPSTONE/RoyalCommission' #data fold path\n",
    "args = 'content'  #data type\n",
    "round=4\n",
    "max_words=2000\n",
    "data = load_data(dir,round,args)\n",
    "# Number of corpus\n",
    "l=len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Financial Services Royal Commission is wrapping up its Darwin hearings that have focussed on the treatment of rural and Indigenous Australians. \\n\\nAmong the revelations has been details of two funeral insurance companies that may have broken the law in targeting Aboriginal and Torres Strait Islander customers.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "def text_cleaning(text):\n",
    "    myText = text.lower()    \n",
    "    # clean and tokenize document string\n",
    "    document_content = myText.split()    \n",
    "    word_list = []\n",
    "    for i in document_content:\n",
    "        x = 0\n",
    "        if (('http' not in i) and ('@' not in i) and ('<.*?>' not in i) and i.isalnum() and (not i in stop_words)):\n",
    "            word_list += [i]\n",
    "        \n",
    "    return word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-processing\n",
    "def preprocessing(text):    \n",
    "    # remove numbers\n",
    "    number_tokens = [re.sub(r'[\\d]', ' ', i) for i in text]\n",
    "    number_tokens = ' '.join(number_tokens).split()\n",
    "     # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in number_tokens]\n",
    "    # remove empty\n",
    "    length_tokens = [i for i in stemmed_tokens if len(i) > 1]\n",
    "    return length_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of article:  620\n",
      "Number of non-empty article vectors:  620\n"
     ]
    }
   ],
   "source": [
    "LabeledSentence1 = gensim.models.doc2vec.TaggedDocument\n",
    "all_content = []\n",
    "texts = []\n",
    "j=0\n",
    "k=0\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "p_stemmer = PorterStemmer()\n",
    "for em in data:           \n",
    "    #Data cleaning\n",
    "    clean_content = text_cleaning(em)\n",
    "    \n",
    "    #Pre-processing\n",
    "    processed_content = preprocessing(clean_content)\n",
    "    \n",
    "    # add tokens to list\n",
    "    if processed_content:\n",
    "        all_content.append(LabeledSentence1(processed_content,[j]))\n",
    "        j+=1\n",
    "        \n",
    "    k+=1\n",
    "\n",
    "print(\"Number of article: \", k)\n",
    "print(\"Number of non-empty article vectors: \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec(all_content, vector_size = 2000, window = 10, min_count = 500, workers=7, dm = 1, \n",
    "                alpha=0.025, min_alpha=0.001)\n",
    "d2v_model.train(all_content, total_examples=d2v_model.corpus_count, epochs=10, start_alpha=0.002, end_alpha=-0.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(575, 0.9913215637207031), (476, 0.9911184310913086), (608, 0.9910399913787842), (522, 0.9909705519676208), (553, 0.9898577332496643), (567, 0.9895543456077576), (218, 0.9895424842834473), (602, 0.9893099665641785), (73, 0.9892160892486572), (245, 0.9892145395278931)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shengyuan/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print (d2v_model.docvecs.most_similar(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['coal', 'kid', 'energi', 'minist', 'josh', 'frydenberg', 'reportedli', 'draft', 'plan', 'bring', 'extra', 'coal', 'ga', 'power', 'attempt', 'squar', 'nation', 'energi', 'guarante', 'coalit', 'australian', 'report', 'coalit', 'mp', 'brief', 'plan', 'nation', 'leader', 'deputi', 'prime', 'minist', 'michael', 'mccormack', 'look', 'lobbi', 'pm', 'malcolm', 'turnbul', 'facilit', 'new', 'coal', 'power', 'relat', 'ndevr', 'environment', 'found', 'australian', 'carbon', 'emiss', 'broke', 'record', 'past', 'act', 'continu', 'threaten', 'block', 'neg', 'emiss', 'target', 'set', 'larg', 'met', 'inquiri', 'nsw', 'doc', 'new', 'south', 'wale', 'health', 'depart', 'launch', 'major', 'inquiri', 'gynaecologist', 'period', 'reportedli', 'mutil', 'perform', 'unnecessari', 'surgeri', 'dozen', 'includ', 'one', 'die', 'inappropri', 'accord', 'health', 'author', 'set', 'independ', 'special', 'counsel', 'inquiri', 'along', 'dedic', 'telephon', 'line', 'nsw', 'hospit', 'dr', 'emil', 'shawki', 'gay', 'inquiri', 'follow', 'string', 'guardian', 'revel', 'women', 'around', 'nsw', 'town', 'tare', 'sustain', 'psycholog', 'trauma', 'relat', 'complic', 'follow', 'mo', 'money', 'mona', 'dark', 'mofo', 'wrap', 'anoth', 'mona', 'founder', 'david', 'walsh', 'respond', 'claim', 'home', 'miss', 'new', 'econom', 'benefit', 'increas', 'mercuri', 'report', 'walsh', 'maintain', 'across', 'hobart', 'especi', 'museum', 'make', 'local', 'effort', 'health', 'wellb', 'civic', 'get', 'crikey', 'free', 'inbox', 'everi', 'weekday', 'morn', 'crikey', 'free', 'worm', 'signup', 'leav', 'field', 'email', 'sign', 'discuss', 'come', 'piec', 'convers', 'univers', 'tasmania', 'professor', 'dr', 'kate', 'booth', 'outlin', 'lack', 'local', 'lord', 'mayor', 'ron', 'christi', 'also', 'cop', 'flack', 'local', 'tourism', 'hospit', 'group', 'dark', 'mofo', 'get', 'crikey', 'free', 'inbox', 'everi', 'weekday', 'morn', 'crikey', 'free', 'worm', 'signup', 'leav', 'field', 'email', 'sign', 'realli', 'said', 'want', 'attack', 'want', 'attack', 'luci', 'work', 'make', 'pay', 'pay', 'plenti', 'give', 'back', 'appar', 'labor', 'way', 'malcolm', 'turnbul', 'amidst', 'attack', 'tax', 'cut', 'prime', 'gambl', 'make', 'odd', 'crikey', 'best', 'yesterday', 'poll', 'bad', 'news', 'liberalswilliam', 'bow', 'time', 'side', 'feder', 'polit', 'byelect', 'turnbul', 'govern', 'enjoy', 'modest', 'moral', 'boost', 'clear', 'victori', 'state', 'seat', 'western', 'australia', 'commerci', 'tv', 'network', 'look', 'attack', 'sbsglenn', 'dyer', 'tv', 'radio', 'network', 'quarter', 'size', 'rival', 'nine', 'sb', 'certainli', 'get', 'skin', 'bigger', 'rememb', 'hugh', 'nine', 'moan', 'seven', 'tim', 'took', 'time', 'deal', 'amber', 'harrison', 'rise', 'cost', 'debt', 'pressur', 'whine', 'mightili', 'public', 'depart', 'enabl', 'cruelti', 'shock', 'discov', 'cruelti', 'go', 'onbernard', 'kean', 'say', 'much', 'agricultur', 'depart', 'bureaucrat', 'known', 'perfect', 'detail', 'extent', 'anim', 'tortur', 'board', 'live', 'sheep', 'export', 'vessel', 'middl', 'east', 'mani', 'year', 'even', 'bring', 'name', 'compani', 'whose', 'export', 'licenc', 'suspend', 'forc', 'public', 'outrag', 'public', 'humili', 'minist', 'final', 'take', 'regulatori', 'action', 'kind', 'studious', 'avoid', 'take', 'bureaucrat', 'even', 'name', 'read', 'trump', 'call', 'depriv', 'immigr', 'illeg', 'cross', 'border', 'due', 'process', 'right', 'ambul', 'boss', 'make', 'unpreced', 'signal', 'new', 'direct', 'former', 'nt', 'polic', 'commission', 'john', 'mcrobert', 'spend', 'night', 'behind', 'bar', 'groundbreak', 'solar', 'river', 'project', 'slash', 'cost', 'renew', 'energi', 'sa', 'home', 'export', 'western', 'australia', 'govern', 'odd', 'fate', 'sheep', 'horror', 'price', 'dreamworld', 'cost', 'cut', 'propos', 'airport', 'rail', 'line', 'could', 'transform', 'west', 'kristina', 'keneal', 'miss', 'promot', 'labor', 'frontbench', 'bank', 'royal', 'hayn', 'reviv', 'terror', 'financi', 'crisi', 'senat', 'would', 'block', 'labor', 'attempt', 'roll', 'back', 'compani', 'tax', 'cut', 'australia', 'spend', 'nearli', 'billion', 'buy', 'unman', 'militari', 'plane', 'america', 'today', 'brisban', 'bank', 'royal', 'commiss', 'examin', 'farm', 'speaker', 'includ', 'anz', 'execut', 'give', 'evid', 'landmark', 'queensland', 'cattl', 'canberra', 'vanuatu', 'prime', 'minist', 'charlot', 'salwai', 'tabimasma', 'attend', 'ceremoni', 'australian', 'war', 'opposit', 'leader', 'bill', 'shorten', 'address', 'day', 'two', 'ceda', 'along', 'speech', 'urban', 'infrastructur', 'citi', 'minist', 'paul', 'fletcher', 'social', 'servic', 'minist', 'dan', 'tabl', 'report', 'implement', 'monitor', 'health', 'budget', 'save', 'member', 'labor', 'parti', 'hold', 'parti', 'room', 'meet', 'final', 'time', 'winter', 'environment', 'group', 'includ', 'australian', 'conserv', 'foundat', 'getup', 'hold', 'vs', 'clean', 'stunt', 'race', 'lawn', 'parliament', 'protest', 'nation', 'energi', 'guarante', 'last', 'sit', 'week', 'august', 'coag', 'meet', 'sydney', 'minist', 'commerc', 'industri', 'civil', 'aviat', 'suresh', 'prabhu', 'deliv', 'growth', 'host', 'asia', 'societi', 'australia', 'hundr', 'miner', 'launch', 'class', 'action', 'allegedli', 'underpaid', 'work', 'biggest', 'director', 'australia', 'network', 'compani', 'bai', 'nathan', 'speak', 'power', 'part', 'breakfast', 'nation', 'mental', 'health', 'commiss', 'chair', 'luci', 'brogden', 'launch', 'australian', 'mental', 'health', 'seek', 'nomin', 'australian', 'contribut', 'either', 'promot', 'mental', 'health', 'prevent', 'treatment', 'mental', 'secretari', 'nsw', 'depart', 'mark', 'launch', 'report', 'develop', 'skill', 'requir', 'children', 'amidst', 'new', 'technolog', 'best', 'worst', 'hobart', 'day', 'two', 'legisl', 'estim', 'hear', 'minist', 'fire', 'emerg', 'scienc', 'michael', 'tasmanian', 'premier', 'melbourn', 'environ', 'plan', 'committe', 'hold', 'public', 'hear', 'inquiri', 'propos', 'leas', 'land', 'titl', 'registri', 'aspect', 'land', 'use', 'univers', 'faculti', 'fine', 'art', 'music', 'host', 'adsa', 'confer', 'act', 'st', 'adelaid', 'south', 'minist', 'energi', 'mine', 'dan', 'van', 'holst', 'pellekaan', 'offici', 'open', 'mine', 'confer', 'sa', 'premier', 'steven', 'marshal', 'driver', 'jami', 'david', 'reynold', 'nick', 'percat', 'launch', 'new', 'supercar', 'event', 'held', 'perth', 'australian', 'institut', 'energi', 'host', 'secur', 'manag', 'transit', 'panel', 'discuss', 'repres', 'aemo', 'western', 'associ', 'servic', 'tortur', 'trauma', 'survivor', 'host', 'public', 'seminar', 'life', 'professor', 'imperi', 'religi', 'histori', 'hilari', 'carey', 'present', 'public', 'lectur', 'bibl', 'australian', 'missionari', 'network', 'theori', 'racial', 'origin', 'th', 'queensland', 'ipswich', 'act', 'mayor', 'wayn', 'wendt', 'citi', 'councillor', 'speak', 'council', 'australia', 'today', 'unit', 'nation', 'intern', 'day', 'support', 'victim', 'england', 'bee', 'gee', 'barri', 'made', 'knight', 'investitur', 'buckingham', 'commentariat', 'cba', 'amput', 'toxic', 'wealth', 'manag', 'arm', 'poison', 'spread', 'adel', 'ferguson', 'morn', 'year', 'commonwealth', 'bank', 'whistleblow', 'jeff', 'morri', 'burst', 'onto', 'scene', 'explos', 'alleg', 'rampant', 'misconduct', 'conflict', 'financi', 'plan', 'bank', 'put', 'white', 'flag', 'vertic', 'big', 'move', 'preempt', 'outcom', 'royal', 'commiss', 'financi', 'everi', 'singl', 'kid', 'current', 'northern', 'youth', 'detent', 'centr', 'indigen', 'sam', 'langford', 'midst', 'northern', 'estim', 'committe', 'debat', 'last', 'week', 'truli', 'harrow', 'young', 'peopl', 'current', 'youth', 'detent', 'northern', 'territori', 'everi', 'singl', 'kid', 'lock', 'northern', 'territori', 'accord', 'ring', 'alarm', 'hold', 'front', 'page', 'share', 'articl'], tags=[2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_content[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(d2v_model.docvecs.vectors_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector=d2v_model.docvecs.vectors_docs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(num_clusters,data):\n",
    "    km = KMeans(n_clusters=num_clusters)\n",
    "    km.fit(data)\n",
    "    clusters = km.labels_.tolist()\n",
    "    score=silhouette_score(data,km.labels_,metric='euclidean')\n",
    "    \n",
    "    return clusters, km.inertia_,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE_list=list()\n",
    "Scores = list()\n",
    "clusters_range = np.arange(2,300,10)\n",
    "\n",
    "# SSE(sum of the squared errors)\n",
    "# Silhouette Coefficient\n",
    "for i in clusters_range:\n",
    "    clusters,SSE,score=k_means(i,doc_vector)\n",
    "    Scores.append(score)\n",
    "    SSE_list.append(SSE)\n",
    "plt.title( 'K Number Vs SSE')\n",
    "plt.xlabel('K Number')\n",
    "plt.ylabel('SSE')\n",
    "plt.plot(clusters_range,SSE_list,'o-')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title( 'K Number Vs Silhouette Coefficient')\n",
    "plt.xlabel('K Number')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.plot(clusters_range,Scores,'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up colors per clusters using a dictclusters,SSE,score=k_means(i,PCA_data)\n",
    "num_clusters=10\n",
    "clusters,SSE,score=k_means(num_clusters,doc_vector)\n",
    "cluster_colors=[]\n",
    "cluster_names =[]\n",
    "\n",
    "cluster_colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(num_clusters)]\n",
    "\n",
    "\n",
    "print(cluster_colors)\n",
    "for i in range(num_clusters):\n",
    "    name=\"Cluster\"+ str (i+1)\n",
    "    cluster_names.append(name)\n",
    "print(cluster_names)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity\n",
    "\n",
    "dist = 1 - cosine_similarity(doc_vector)\n",
    "\n",
    "# For plotting purpose\n",
    "pca = PCA(n_components=2, copy=True)\n",
    "pos = pca.fit_transform(dist) # shape (n_components, n_samples)\n",
    "xs, ys = pos[:, 0], pos[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some ipython magic to show the matplotlib plots inline\n",
    "%matplotlib inline \n",
    "\n",
    "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=np.arange(1,pos.shape[0]+1))) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "# set up plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "            label=cluster_names[name], color=cluster_colors[name], \n",
    "            mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         # changes apply to the y-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)  #show legend with only 1 point\n",
    "\n",
    "#add label in x,y position with the label as the film title\n",
    "for i in range(len(df)):\n",
    "    ax.text(df.loc[df.index[i],'x'], df.loc[df.index[i],'y'], df.loc[df.index[i],'title'], size=7)  \n",
    "    \n",
    "plt.show() #show the plot\n",
    "\n",
    "#uncomment the below to save the plot if need be\n",
    "#plt.savefig('clusters_small_noaxes.png', dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
